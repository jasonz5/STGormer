## global
seed: 31
device: cuda
mode: train
best_path: Null
debug: True # true means no log in file

## data
data_dir: data
dataset: BJTaxi 
input_length: 35 # 8+9*3
batch_size: 4  # 8 will cause oom
test_batch_size: 4
graph_file: data/BJTaxi/adj_mx.npz # num_nodes: 1024

## model 
d_input: 2                  # means inflow and outflow
d_output: 2                 # means inflow and outflow
d_model: 64
num_heads: 4
mlp_ratio: 4
encoder_depth: 1
dropout: 0.1
yita: 0.5                   # balance for inflow loss and outflow loss, $yita * inflow + (1 - yita) * outflow$

## train
epochs: 250
lr_init: 1.0e-4        # 0.001
scheduler: 'MultiStepLR'
milestones: [120, 140, 160, 180, 200]
gamma: 0.9
early_stop: True
early_stop_patience: 25
grad_norm: True
max_grad_norm: 5
use_dwa: False         # whether to use dwa for loss balance
temp: 2               # tempurature parameter in dwa, a larger T means more similer weights
